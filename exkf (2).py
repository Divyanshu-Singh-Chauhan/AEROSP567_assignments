# -*- coding: utf-8 -*-
"""ExKF.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f8OZsLF7jDOvi9hL1oEUzddX2cF3-raB

# Extended Kalman Filter
"""

#%matplotlib widget
from typing import Tuple, List, Optional
from dataclasses import dataclass
from functools import partial
import numpy as np
import matplotlib.pyplot as plt
from ipywidgets import interact_manual


import matplotlib
LW=5 # linewidth
MS=10 # markersize

# No change
@dataclass
class Gaussian:
    mean: np.ndarray
    cov: np.ndarray

@dataclass
class Observations:
    times: np.ndarray
    obs_ind: np.ndarray  # index of times that are observed
    obs: np.ndarray
    names: List[str]

@dataclass
class KFTracker:
    means: np.ndarray
    covs: np.ndarray
    stds: np.ndarray

# SINGLE PREDICT AND UPDATE STEP

def linear_prediction_step(A: np.ndarray, X: Gaussian, xi: Gaussian, dt:float) -> Gaussian:
    pred_mean = pendulum_dyn(X.mean,dt)
    pred_cov = np.dot(A, np.dot(X.cov, A.T)) + xi.cov
    return Gaussian(pred_mean, pred_cov)

def linear_update_step(data: np.ndarray, H: np.ndarray, X: Gaussian, eta: Gaussian):
    U = np.dot(X.cov, H.T)
    S = np.dot(H, U) + eta.cov
    mu = np.dot(H, X.mean) + eta.mean


    update_mean = X.mean + np.dot(U, np.linalg.solve(S, data - mu))
    update_cov = X.cov - np.dot(U, np.linalg.solve(S, U.T))
    return Gaussian(update_mean, update_cov)

def jacobian_dynamics(x_mean, dt):
    """Compute Jacobian of the dynamics."""
    A = np.array([
        [1, dt],
        [-dt * 9.81 * np.cos(x_mean[0]), 1]
    ])
    return A

def jacobian_observation(x_mean):
    """Compute Jacobian of the observation."""
    H = np.array([[np.cos(x_mean[0]), 0]])
    return H

# Need to make change in the code
# Changes needed are :
# 1. make changes in the update step to update only at the delta time steps (make the same change in the generation data function)
# 2. A and H will be time-varying thus while doing prediction, make the changes directly while doing the prediction and update step.
# 3. Time Steps should be 500

def extended_kalman_filter(data: Observations,
                  X: Gaussian,
                  xi: Gaussian, eta: Gaussian, N:int, delta:int, dt:float) -> Tuple[np.ndarray, np.ndarray]:
    """The Kalman filter.

    Inputs
    ------
    data: (N, m), N is the number of time steps, m is the size of the observations
    X: prior Gaussian
    xi: process noise
    eta: measurement noise

    Return
    ------
    KFTracker

    Note
    ----
    Assumes timestep of dynamics is the same as data! Will have to update for projects
    """

    num_steps = N

    d = X.mean.shape[0]
    mean_store = np.zeros((num_steps, d))
    mean_store[0, :] = np.copy(X.mean)
    cov_store = np.zeros((num_steps, d, d))
    cov_store[0, :, :] = np.copy(X.cov)

    std_store = np.zeros((num_steps, d))
    std_store[0, :] = np.sqrt(np.diag(cov_store[0, :, :]))

    #Loop over all time steps
    Xnext = X
    on_obs = 0
    obs_freq = delta
    obs_ind = np.arange(obs_freq, num_steps, obs_freq)
    for ii in range(1, num_steps):

        # Prediction
        # make changes in the A_k and H_k and send it to the linear_prediction and update step. (DONE)
        A_k = jacobian_dynamics(x_mean=Xnext.mean,dt=dt)
        Xpred = linear_prediction_step(A_k, Xnext, xi,dt)

        # We have an observation so an update must occur
        # DEBUG: Change for our project. The frequency needs to be changed ...
        # if on_obs < data.obs_ind.shape[0] and ii == data.obs_ind[on_obs]:
        if on_obs < data.obs_ind.shape[0] and ii in obs_ind:
            y = data.obs[on_obs]
            on_obs += 1

            # Update
            H_k = jacobian_observation(Xnext.mean)
            Xup = linear_update_step(y, H_k, Xpred, eta)
            Xnext = Xup

        else:
            Xnext = Xpred

        mean_store[ii, :] = np.copy(Xnext.mean)
        cov_store[ii, : ,:] = np.copy(Xnext.cov)
        std_store[ii, :] = np.sqrt(np.diag(cov_store[ii, :, :]))

    return KFTracker(mean_store, cov_store, std_store)

def pendulum_dyn(current_state, dt):
    """Pendulum dynamics

    Inputs
    ------
    Current_state : either (2,) or (N, 2) for vectorized input
    """
    if current_state.ndim == 1:
        next_state = np.zeros((2))
        next_state[0] = current_state[0] + dt * current_state[1]
        next_state[1] = current_state[1] - dt * 9.81 * np.sin(current_state[0])
    else: # multiple inputs
        next_state = np.zeros(current_state.shape)
        next_state[:, 0] = current_state[:, 0] + dt * current_state[:, 1]
        next_state[:, 1] = current_state[:, 1] - dt * 9.81 * np.sin(current_state[:, 0])
    return next_state

def observe(current_state):
    if current_state.ndim == 1:
        out = np.zeros((1))
        out[0] = np.sin(current_state[0])
    else:
        out = np.zeros((current_state.shape[0], 1))
        out[:, 0] = np.sin(current_state[:, 0])
    return out

# Compute the Mean Squared Error (MSE) for tracking position and velocity
def compute_mse(true_state, estimated_states):
    """Compute Mean Squared Error (MSE) between true states and estimated states."""
    mse_position = np.mean((true_state[:, 0] - estimated_states[:, 0])**2)  # MSE for position
    mse_velocity = np.mean((true_state[:, 1] - estimated_states[:, 1])**2)  # MSE for velocity
    return mse_position, mse_velocity


# Generate Data
def generate_data(N, R, delta,dt):
  x0 = np.array([1.5, 0])
  Nsteps = N
  true = np.zeros((Nsteps, 2))
  true[0, :] = x0
  times = np.arange(0, Nsteps*dt, dt)
  data = np.zeros((Nsteps-1, 1))
  meas_noise = R # standard deviation of measure noise # 1, 0.1, 0.01, 0.001
  obs_names = ['s1', 's2']
  on_obs = 0
  obs_freq = delta
  obs_ind = np.arange(obs_freq, Nsteps, obs_freq)
  noise_var = R
  for ii in range(1, Nsteps):
      true[ii, :] = pendulum_dyn(true[ii-1, :],dt=dt)
      if on_obs < obs_ind.shape[0] and ii == obs_ind[on_obs]:
        data[ii-1] = observe(true[ii, :]) + np.random.randn()*np.sqrt(meas_noise)
        on_obs += 1

  v_data = []
  t_data = []
  for dd in range(data.shape[0]):
    if data[dd]:
      v_data.append(data[dd])
      t_data.append(times[dd-1])


  truth = Observations(times, np.arange(Nsteps), true, ['state0', 'state1'])
  noisy_obs = Observations(np.array(t_data), obs_ind, np.array(v_data), obs_names)

  return truth, noisy_obs

import matplotlib.pyplot as plt
from typing import Optional

def plot_data_and_truth(ax, true_obs: Observations, data_obs: Observations,
                        kft: Optional[KFTracker] = None):
    colors = ['red', 'blue', 'green']

    # Plot true observations on the given axes
    ax.plot(true_obs.times, true_obs.obs[:, 0], color=colors[0], label='state0')
    ax.plot(true_obs.times, true_obs.obs[:, 1], color=colors[1], label='state1')

    # Plot Kalman filter results if available
    if kft is not None:
        ax.plot(true_obs.times, kft.means[:, 0], '--', color=colors[0], label='est-state0')
        ax.plot(true_obs.times, kft.means[:, 1], '--', color=colors[1], label='est-state1')
        ax.fill_between(true_obs.times,
                         kft.means[:, 0] - 2 * kft.stds[:, 0],
                         kft.means[:, 0] + 2 * kft.stds[:, 0],
                         color=colors[0], alpha=0.3)
        ax.fill_between(true_obs.times,
                         kft.means[:, 1] - 2 * kft.stds[:, 1],
                         kft.means[:, 1] + 2 * kft.stds[:, 1],
                         color=colors[1], alpha=0.3)

    ax.legend()
    ax.set_xlabel('Time', fontsize=14)
    ax.set_ylabel('State Estimate', fontsize=14)

# PRIOR
X0 = Gaussian(np.array([1.5,0]), np.eye(2))

obs_names = ['s1', 's2']
H = np.eye(1)
N = 100
R = 1 # 1, 0.1, 0.01,0.001
R = [1,0.1,0.01,0.001]
delta = 5 # 5,10,20,40
dt=0.01
Q = np.array([[3.33e-9, 5.0e-7],[5.0e-7, 1.0e-4]])
process_noise = Gaussian(0, Q)  # Process noise covariance

R = [1,0.1,0.01,0.001]
delta = [5,10,20,40]

fig, axs = plt.subplots(4, 4, figsize=(15, 15))

for i,r in enumerate(R):
  for j,d in enumerate(delta):
    truth, noisy_obs = generate_data(N, r, d,dt)

    meas_noise = Gaussian(0, r)
    kf_res = extended_kalman_filter(noisy_obs, X0, process_noise, meas_noise,N ,d, dt)

    # Calculate MSE for position and velocity
    mse_position, mse_velocity = compute_mse(truth.obs, kf_res.means)
    print(f"Mean Squared Error for Position for R={r}, δ={d}: {mse_position}")
    print(f"Mean Squared Error for Velocity for R={r}, δ={d}: {mse_velocity}")
    print(" ------ ")

    ax = axs[i, j]  # Select the subplot (i-th row, j-th column)
    plot_data_and_truth(ax, truth, noisy_obs, kf_res)

    ax.set_title(f"R={r}, δ={d}")

plt.tight_layout()
plt.show()

"""# Unscented Kalman Filtering"""

def generate_sigma(X: Gaussian, alpha: float, beta: float, kappa: float) -> Tuple[np.ndarray, np.ndarray]:

    n = X.mean.size  # Dimension
    lambda_ = alpha**2 * (n + kappa) - n
    Wm = np.zeros(2 * n + 1)
    Wc = np.zeros(2 * n + 1)

    Wm[0] = lambda_ / (n + lambda_)
    Wc[0] = Wm[0] + (1 - alpha**2 + beta)
    Wm[1:] = 1 / (2 * (n + lambda_))
    Wc[1:] = Wm[1:]

    sigma_points = np.zeros((2 * n + 1, n))
    sqrt_P = np.linalg.cholesky((n + lambda_) * X.cov)
    sigma_points[0] = X.mean
    for i in range(n):
        sigma_points[i + 1] = X.mean + sqrt_P[i]
        sigma_points[n + i + 1] = X.mean - sqrt_P[i]

    return sigma_points, Wm, Wc


def unscented_trans(sigma_points: np.ndarray, Wm: np.ndarray, Wc: np.ndarray, noise_cov: np.ndarray):
    """Transform sigma points and recompute mean and covariance."""
    mean = np.sum(Wm[:, None] * sigma_points, axis=0)
    diff = sigma_points - mean
    cov = np.dot(Wc * diff.T, diff) + noise_cov
    return mean, cov


def unscented_kalman_filter(data: Observations,
                            X: Gaussian,
                            xi: Gaussian, eta: Gaussian, N: int, delta,dt) -> KFTracker:
    """Unscented Kalman Filter."""
    num_steps = N
    d = X.mean.size
    mean_store = np.zeros((num_steps, d))
    cov_store = np.zeros((num_steps, d, d))
    std_store = np.zeros((num_steps, d))

    mean_store[0] = X.mean
    cov_store[0] = X.cov
    std_store[0] = np.sqrt(np.diag(X.cov))

    alpha = 0.001  # Spread of the sigma points
    beta = 2.0     # Optimal for Gaussian distributions
    kappa = 0.0    # Secondary scaling parameter

    on_obs = 0
    obs_freq = delta
    obs_ind = np.arange(obs_freq, num_steps, obs_freq)

    Xnext = X

    for ii in range(1, num_steps):
        # Generate sigma points
        sigma_points, Wm, Wc = generate_sigma(Xnext, alpha, beta, kappa)

        # Prediction step: Pass sigma points through dynamics
        sigma_points_pred = np.array([pendulum_dyn(sigma,dt) for sigma in sigma_points])
        pred_mean, pred_cov = unscented_trans(sigma_points_pred, Wm, Wc, xi.cov)

        Xpred = Gaussian(pred_mean, pred_cov)

        # Update step
        if on_obs < data.obs_ind.shape[0] and ii in obs_ind:
            y = data.obs[on_obs]
            on_obs += 1

            # Transform sigma points through observation model
            sigma_points_obs = np.array([observe(sigma) for sigma in sigma_points_pred])
            obs_mean, obs_cov = unscented_trans(sigma_points_obs, Wm, Wc, eta.cov)

            # Cross covariance
            cross_cov = np.dot(
                Wc * (sigma_points_pred - pred_mean).T,
                (sigma_points_obs - obs_mean)
            )

            # Kalman gain
            K = np.dot(cross_cov, np.linalg.inv(obs_cov))

            # Update mean and covariance
            update_mean = pred_mean + np.dot(K, y - obs_mean)
            update_cov = pred_cov - np.dot(K, np.dot(obs_cov, K.T))

            Xnext = Gaussian(update_mean, update_cov)
        else:
            Xnext = Xpred

        mean_store[ii, :] = Xnext.mean
        cov_store[ii, :, :] = Xnext.cov
        std_store[ii, :] = np.sqrt(np.diag(Xnext.cov))

    return KFTracker(mean_store, cov_store, std_store)

obs_names = ['s1', 's2']
H = np.eye(1)
N = 100
R = 1 # 1, 0.1, 0.01,0.001
R = [1,0.1,0.01,0.001]
delta = 5 # 5,10,20,40
dt=0.01
Q = np.array([[3.33e-9, 5.0e-7],[5.0e-7, 1.0e-4]])
process_noise = Gaussian(0, Q)  # Process noise covariance

R = [1,0.1,0.01,0.001]
delta = [5,10,20,40]

fig, axs = plt.subplots(4, 4, figsize=(15, 15))

for i,r in enumerate(R):
  for j,d in enumerate(delta):
    truth, noisy_obs = generate_data(N, r, d,dt)

    meas_noise = Gaussian(0, r)
    kf_res = unscented_kalman_filter(noisy_obs, X0, process_noise, meas_noise,N ,d,dt)

    # Calculate MSE for position and velocity
    mse_position, mse_velocity = compute_mse(truth.obs, kf_res.means)
    print(f"Mean Squared Error for Position for R={r}, δ={d}: {mse_position}")
    print(f"Mean Squared Error for Velocity for R={r}, δ={d}: {mse_velocity}")
    print(" ------ ")

    ax = axs[i, j]  # Select the subplot (i-th row, j-th column)
    plot_data_and_truth(ax, truth, noisy_obs, kf_res)

    ax.set_title(f"R={r}, δ={d}")

plt.tight_layout()
plt.show()

"""# GAUSS HERMITE KF"""

import scipy.stats as stats

def hermite_points(mean: np.ndarray, cov: np.ndarray, order: int = 3):
    n = mean.size
    gh_points, gh_weights = np.polynomial.hermite.hermgauss(order)
    gh_weights /= np.sqrt(np.pi)  # Normalize weights

    sigma_points = []
    weights = []

    sqrt_cov = np.linalg.cholesky(cov)
    for i in range(order):
        for j in range(order):
            z = np.array([gh_points[i], gh_points[j]])
            sigma_point = mean + np.dot(sqrt_cov, z)
            weight = gh_weights[i] * gh_weights[j]
            sigma_points.append(sigma_point)
            weights.append(weight)

    return np.array(sigma_points), np.array(weights)


def gauss_hermite_kalman_filter(data: Observations,
                                X: Gaussian,
                                xi: Gaussian, eta: Gaussian,
                                N: int, delta: int, dt: float,
                                order: int = 3) -> KFTracker:
    num_steps = N
    d = X.mean.size
    mean_store = np.zeros((num_steps, d))
    cov_store = np.zeros((num_steps, d, d))
    std_store = np.zeros((num_steps, d))

    mean_store[0] = X.mean
    cov_store[0] = X.cov
    std_store[0] = np.sqrt(np.diag(X.cov))

    on_obs = 0
    obs_freq = delta
    obs_ind = np.arange(obs_freq, num_steps, obs_freq)

    Xnext = X

    for ii in range(1, num_steps):
        sigma_points, weights = hermite_points(Xnext.mean, Xnext.cov, order)

        # Prediction
        sigma_points_pred = np.array([pendulum_dyn(sigma, dt) for sigma in sigma_points])
        pred_mean = np.sum(weights[:, None] * sigma_points_pred, axis=0)
        diff_pred = sigma_points_pred - pred_mean
        pred_cov = np.dot(weights * diff_pred.T, diff_pred) + xi.cov

        Xpred = Gaussian(pred_mean, pred_cov)

        # Update
        if on_obs < data.obs_ind.shape[0] and ii in obs_ind:
            y = data.obs[on_obs]
            on_obs += 1

            # Transforming sigma points through observation model
            sigma_points_obs = np.array([observe(sigma) for sigma in sigma_points_pred])
            obs_mean = np.sum(weights[:, None] * sigma_points_obs, axis=0)
            diff_obs = sigma_points_obs - obs_mean
            obs_cov = np.dot(weights * diff_obs.T, diff_obs) + eta.cov

            cross_cov = np.dot(weights * diff_pred.T, diff_obs)

            # gain
            K = np.dot(cross_cov, np.linalg.inv(obs_cov))

            # Updating mean and covariance
            update_mean = pred_mean + np.dot(K, y - obs_mean)
            update_cov = pred_cov - np.dot(K, np.dot(obs_cov, K.T))

            Xnext = Gaussian(update_mean, update_cov)
        else:
            Xnext = Xpred

        mean_store[ii, :] = Xnext.mean
        cov_store[ii, :, :] = Xnext.cov
        std_store[ii, :] = np.sqrt(np.diag(Xnext.cov))

    return KFTracker(mean_store, cov_store, std_store)


# Testing the Gauss-Hermite Kalman Filter
fig, axs = plt.subplots(4, 4, figsize=(15, 15))

for i, r in enumerate(R):
    for j, d in enumerate(delta):
        truth, noisy_obs = generate_data(N, r, d, dt)

        meas_noise = Gaussian(0, r)
        kf_res = gauss_hermite_kalman_filter(noisy_obs, X0, process_noise, meas_noise, N, d, dt, order=3)

        # Calculate MSE for position and velocity
        mse_position, mse_velocity = compute_mse(truth.obs, kf_res.means)
        print(f"Mean Squared Error for Position for R={r}, δ={d}: {mse_position}")
        print(f"Mean Squared Error for Velocity for R={r}, δ={d}: {mse_velocity}")
        print(" ------ ")

        ax = axs[i, j]
        plot_data_and_truth(ax, truth, noisy_obs, kf_res)

        ax.set_title(f"R={r}, δ={d}")

plt.tight_layout()
plt.show()

